"""
Task Classification Framework
============================
å€åˆ†é–‹æ”¾æ€§æ¨ç† vs çµæ§‹åŒ–ä»»å‹™ï¼Œé¸æ“‡æœ€é©åˆçš„promptç­–ç•¥
"""

import re
from typing import Dict, List, Tuple
from enum import Enum

class TaskType(Enum):
    STRUCTURED_EXTRACTION = "structured_extraction"      # çµæ§‹åŒ–æå–
    OPEN_REASONING = "open_reasoning"                    # é–‹æ”¾æ€§æ¨ç†
    ANALYTICAL_REASONING = "analytical_reasoning"        # åˆ†ææ€§æ¨ç†
    CREATIVE_GENERATION = "creative_generation"          # å‰µæ„ç”Ÿæˆ
    FACTUAL_QA = "factual_qa"                           # äº‹å¯¦å•ç­”
    PROBLEM_SOLVING = "problem_solving"                  # å•é¡Œè§£æ±º

class TaskClassifier:
    """ä»»å‹™é¡å‹åˆ†é¡å™¨"""
    
    def __init__(self):
        # çµæ§‹åŒ–ä»»å‹™çš„é—œéµæŒ‡æ¨™
        self.structured_indicators = {
            'output_format': [
                'JSON', 'json', 'CSV', 'xml', 'YAML', 'table', 'list',
                'è¡¨æ ¼', 'æ¸…å–®', 'æ ¼å¼', 'æ¬„ä½', 'éµå€¼', 'key-value'
            ],
            'extraction_verbs': [
                'extract', 'parse', 'identify', 'classify', 'categorize',
                'label', 'tag', 'segment', 'detect',
                'æå–', 'è§£æ', 'è­˜åˆ¥', 'åˆ†é¡', 'æ¨™è¨˜', 'æª¢æ¸¬', 'æ­¸é¡'
            ],
            'fixed_schema': [
                'sentiment', 'product', 'issue', 'category', 'label',
                'score', 'rating', 'class', 'type', 'status',
                'æƒ…æ„Ÿ', 'ç”¢å“', 'å•é¡Œ', 'é¡åˆ¥', 'è©•åˆ†', 'ç‹€æ…‹'
            ]
        }
        
        # é–‹æ”¾æ€§æ¨ç†çš„é—œéµæŒ‡æ¨™
        self.reasoning_indicators = {
            'reasoning_verbs': [
                'explain', 'analyze', 'discuss', 'evaluate', 'compare',
                'argue', 'justify', 'reason', 'conclude', 'infer',
                'è§£é‡‹', 'åˆ†æ', 'è¨è«–', 'è©•ä¼°', 'æ¯”è¼ƒ', 'è«–è­‰', 'æ¨ç†', 'æ¨æ–·'
            ],
            'open_questions': [
                'why', 'how', 'what if', 'suppose', 'consider',
                'explore', 'investigate', 'think about',
                'ç‚ºä»€éº¼', 'å¦‚ä½•', 'å‡å¦‚', 'å‡è¨­', 'è€ƒæ…®', 'æ¢è¨', 'æ€è€ƒ'
            ],
            'creative_tasks': [
                'create', 'generate', 'design', 'invent', 'imagine',
                'brainstorm', 'propose', 'suggest',
                'å‰µé€ ', 'ç”Ÿæˆ', 'è¨­è¨ˆ', 'ç™¼æ˜', 'æƒ³åƒ', 'å»ºè­°', 'æè­°'
            ]
        }
        
        # æœ€é©ç­–ç•¥æ˜ å°„
        self.strategy_mapping = {
            TaskType.STRUCTURED_EXTRACTION: ['rules_based', 'few_shot'],
            TaskType.OPEN_REASONING: ['cot', 'react'],
            TaskType.ANALYTICAL_REASONING: ['cot', 'react', 'few_shot'],
            TaskType.CREATIVE_GENERATION: ['react', 'cot'],
            TaskType.FACTUAL_QA: ['rules_based', 'few_shot'],
            TaskType.PROBLEM_SOLVING: ['react', 'cot']
        }

    def analyze_task_characteristics(self, prompt: str) -> Dict[str, float]:
        """åˆ†æä»»å‹™ç‰¹å¾µ"""
        prompt_lower = prompt.lower()
        
        characteristics = {
            'has_fixed_format': 0.0,
            'extraction_focus': 0.0,
            'reasoning_complexity': 0.0,
            'creativity_required': 0.0,
            'open_ended_nature': 0.0,
            'structured_output': 0.0
        }
        
        # æª¢æ¸¬å›ºå®šæ ¼å¼è¦æ±‚
        format_count = sum(1 for indicator in self.structured_indicators['output_format'] 
                          if indicator.lower() in prompt_lower)
        characteristics['has_fixed_format'] = min(format_count / 3, 1.0)
        
        # æª¢æ¸¬æå–æ€§å‹•è©
        extract_count = sum(1 for verb in self.structured_indicators['extraction_verbs']
                           if verb.lower() in prompt_lower)
        characteristics['extraction_focus'] = min(extract_count / 3, 1.0)
        
        # æª¢æ¸¬æ¨ç†æ€§å‹•è©
        reasoning_count = sum(1 for verb in self.reasoning_indicators['reasoning_verbs']
                             if verb.lower() in prompt_lower)
        characteristics['reasoning_complexity'] = min(reasoning_count / 3, 1.0)
        
        # æª¢æ¸¬å‰µæ„æ€§å‹•è©
        creative_count = sum(1 for verb in self.reasoning_indicators['creative_tasks']
                            if verb.lower() in prompt_lower)
        characteristics['creativity_required'] = min(creative_count / 2, 1.0)
        
        # æª¢æ¸¬é–‹æ”¾æ€§å•é¡Œ
        open_count = sum(1 for question in self.reasoning_indicators['open_questions']
                        if question.lower() in prompt_lower)
        characteristics['open_ended_nature'] = min(open_count / 2, 1.0)
        
        # æª¢æ¸¬çµæ§‹åŒ–è¼¸å‡ºè¦æ±‚
        schema_count = sum(1 for field in self.structured_indicators['fixed_schema']
                          if field.lower() in prompt_lower)
        characteristics['structured_output'] = min(schema_count / 2, 1.0)
        
        return characteristics

    def classify_task(self, prompt: str) -> Tuple[TaskType, float, str]:
        """åˆ†é¡ä»»å‹™é¡å‹"""
        characteristics = self.analyze_task_characteristics(prompt)
        
        # è¨ˆç®—å„é¡å‹çš„å¾—åˆ†
        scores = {}
        
        # çµæ§‹åŒ–æå–
        scores[TaskType.STRUCTURED_EXTRACTION] = (
            characteristics['has_fixed_format'] * 0.3 +
            characteristics['extraction_focus'] * 0.3 +
            characteristics['structured_output'] * 0.4
        )
        
        # é–‹æ”¾æ€§æ¨ç†
        scores[TaskType.OPEN_REASONING] = (
            characteristics['reasoning_complexity'] * 0.4 +
            characteristics['open_ended_nature'] * 0.6
        )
        
        # åˆ†ææ€§æ¨ç†
        scores[TaskType.ANALYTICAL_REASONING] = (
            characteristics['reasoning_complexity'] * 0.5 +
            characteristics['structured_output'] * 0.3 +
            characteristics['extraction_focus'] * 0.2
        )
        
        # å‰µæ„ç”Ÿæˆ
        scores[TaskType.CREATIVE_GENERATION] = (
            characteristics['creativity_required'] * 0.6 +
            characteristics['open_ended_nature'] * 0.4
        )
        
        # äº‹å¯¦å•ç­” (æœ‰çµæ§‹ä½†ä¸éœ€è¤‡é›œæ¨ç†)
        scores[TaskType.FACTUAL_QA] = (
            characteristics['extraction_focus'] * 0.4 +
            (1 - characteristics['reasoning_complexity']) * 0.3 +
            (1 - characteristics['open_ended_nature']) * 0.3
        )
        
        # å•é¡Œè§£æ±º
        scores[TaskType.PROBLEM_SOLVING] = (
            characteristics['reasoning_complexity'] * 0.4 +
            characteristics['open_ended_nature'] * 0.3 +
            characteristics['creativity_required'] * 0.3
        )
        
        # æ‰¾å‡ºæœ€é«˜åˆ†çš„ä»»å‹™é¡å‹
        best_task_type = max(scores.items(), key=lambda x: x[1])
        
        # ç”Ÿæˆè§£é‡‹
        explanation = self._generate_explanation(best_task_type[0], characteristics)
        
        return best_task_type[0], best_task_type[1], explanation

    def _generate_explanation(self, task_type: TaskType, characteristics: Dict[str, float]) -> str:
        """ç”Ÿæˆåˆ†é¡è§£é‡‹"""
        explanations = {
            TaskType.STRUCTURED_EXTRACTION: f"çµæ§‹åŒ–æå–ä»»å‹™ - å›ºå®šæ ¼å¼: {characteristics['has_fixed_format']:.2f}, çµæ§‹åŒ–è¼¸å‡º: {characteristics['structured_output']:.2f}",
            TaskType.OPEN_REASONING: f"é–‹æ”¾æ€§æ¨ç†ä»»å‹™ - æ¨ç†è¤‡é›œåº¦: {characteristics['reasoning_complexity']:.2f}, é–‹æ”¾æ€§: {characteristics['open_ended_nature']:.2f}",
            TaskType.ANALYTICAL_REASONING: f"åˆ†ææ€§æ¨ç†ä»»å‹™ - æ¨ç†è¤‡é›œåº¦: {characteristics['reasoning_complexity']:.2f}, çµæ§‹åŒ–: {characteristics['structured_output']:.2f}",
            TaskType.CREATIVE_GENERATION: f"å‰µæ„ç”Ÿæˆä»»å‹™ - å‰µæ„éœ€æ±‚: {characteristics['creativity_required']:.2f}, é–‹æ”¾æ€§: {characteristics['open_ended_nature']:.2f}",
            TaskType.FACTUAL_QA: f"äº‹å¯¦å•ç­”ä»»å‹™ - æå–å°å‘: {characteristics['extraction_focus']:.2f}, ä½æ¨ç†éœ€æ±‚",
            TaskType.PROBLEM_SOLVING: f"å•é¡Œè§£æ±ºä»»å‹™ - æ¨ç†è¤‡é›œåº¦: {characteristics['reasoning_complexity']:.2f}, å‰µæ„: {characteristics['creativity_required']:.2f}"
        }
        return explanations.get(task_type, "æœªçŸ¥ä»»å‹™é¡å‹")

    def recommend_strategy(self, prompt: str) -> Dict[str, any]:
        """æ¨è–¦æœ€é©ç­–ç•¥"""
        task_type, confidence, explanation = self.classify_task(prompt)
        recommended_strategies = self.strategy_mapping.get(task_type, ['few_shot'])
        
        return {
            'task_type': task_type.value,
            'confidence': confidence,
            'explanation': explanation,
            'recommended_strategies': recommended_strategies,
            'primary_strategy': recommended_strategies[0] if recommended_strategies else 'few_shot'
        }

def demonstrate_task_classification():
    """æ¼”ç¤ºä»»å‹™åˆ†é¡"""
    classifier = TaskClassifier()
    
    # æ¸¬è©¦æ¡ˆä¾‹
    test_prompts = [
        # çµæ§‹åŒ–æå–
        "Extract sentiment, product, and issue from this review. Return as JSON.",
        "Parse the following text and classify it into categories.",
        
        # é–‹æ”¾æ€§æ¨ç†  
        "Why do you think this product failed in the market? Explain your reasoning.",
        "Analyze the implications of this business decision and discuss potential outcomes.",
        
        # åˆ†ææ€§æ¨ç†
        "Compare these two approaches and evaluate which is more effective.",
        "Examine this data and provide insights with supporting evidence.",
        
        # å‰µæ„ç”Ÿæˆ
        "Generate three creative marketing strategies for this product.",
        "Design an innovative solution to this problem.",
        
        # äº‹å¯¦å•ç­”
        "What is the capital of France?",
        "List the main features mentioned in this product description.",
        
        # å•é¡Œè§£æ±º
        "How would you solve this technical issue step by step?",
        "Devise a plan to improve customer satisfaction based on these complaints."
    ]
    
    categories = [
        "çµæ§‹åŒ–æå–", "çµæ§‹åŒ–æå–",
        "é–‹æ”¾æ€§æ¨ç†", "é–‹æ”¾æ€§æ¨ç†", 
        "åˆ†ææ€§æ¨ç†", "åˆ†ææ€§æ¨ç†",
        "å‰µæ„ç”Ÿæˆ", "å‰µæ„ç”Ÿæˆ",
        "äº‹å¯¦å•ç­”", "äº‹å¯¦å•ç­”",
        "å•é¡Œè§£æ±º", "å•é¡Œè§£æ±º"
    ]
    
    print("=" * 80)
    print("  TASK CLASSIFICATION DEMONSTRATION")
    print("=" * 80)
    
    for i, (prompt, expected) in enumerate(zip(test_prompts, categories), 1):
        print(f"\nğŸ“ Test {i}: {expected}")
        print("-" * 70)
        print(f"Prompt: {prompt}")
        
        recommendation = classifier.recommend_strategy(prompt)
        
        print(f"ğŸ¯ Classified as: {recommendation['task_type']}")
        print(f"ğŸ“Š Confidence: {recommendation['confidence']:.2f}")
        print(f"ğŸ’¡ Explanation: {recommendation['explanation']}")
        print(f"ğŸš€ Recommended strategies: {recommendation['recommended_strategies']}")
        print(f"â­ Primary strategy: {recommendation['primary_strategy']}")

def create_improved_strategy_predictor():
    """å‰µå»ºæ”¹é€²çš„ç­–ç•¥é åˆ¤å™¨"""
    print("""
ğŸ”§ **æ”¹é€²çš„ç­–ç•¥é¸æ“‡ç³»çµ±**ï¼š

```python
class ImprovedStrategyPredictor:
    def __init__(self):
        self.task_classifier = TaskClassifier()
        self.complexity_analyzer = ComplexityAnalyzer()
    
    def predict_optimal_strategy(self, prompt, user_input=""):
        # 1. åˆ†æä»»å‹™é¡å‹
        task_recommendation = self.task_classifier.recommend_strategy(prompt)
        
        # 2. åˆ†æè¼¸å…¥è¤‡é›œåº¦  
        complexity_score = self.complexity_analyzer.analyze(user_input)
        
        # 3. ç¶œåˆæ±ºç­–
        if task_recommendation['task_type'] == 'structured_extraction':
            if complexity_score < 0.3:
                return 'rules_based'
            else:
                return 'few_shot'
        
        elif task_recommendation['task_type'] == 'open_reasoning':
            if complexity_score < 0.5:
                return 'cot'
            else:
                return 'react'
        
        # 4. å…¶ä»–é¡å‹çš„é‚è¼¯...
        return task_recommendation['primary_strategy']
```

**é—œéµæ”¹é€²**ï¼š
1. ğŸ¯ ä»»å‹™é¡å‹å°å‘çš„ç­–ç•¥é¸æ“‡
2. ğŸ“Š è¤‡é›œåº¦åˆ†æä½œç‚ºè¼”åŠ©åˆ¤æ–·
3. ğŸ”„ å‹•æ…‹é©æ‡‰ä¸åŒä»»å‹™éœ€æ±‚
4. âœ… é¿å…ç­–ç•¥èˆ‡ä»»å‹™é¡å‹ä¸åŒ¹é…
""")

if __name__ == "__main__":
    demonstrate_task_classification()
    create_improved_strategy_predictor()
    
    print("""
âœ… **ç¸½çµ - å¦‚ä½•å€åˆ†é–‹æ”¾æ€§æ¨ç† vs çµæ§‹åŒ–ä»»å‹™**ï¼š

ğŸ“‹ **çµæ§‹åŒ–ä»»å‹™ç‰¹å¾µ**ï¼š
- æ˜ç¢ºçš„è¼¸å‡ºæ ¼å¼è¦æ±‚ (JSON, CSV, è¡¨æ ¼ç­‰)
- æå–æ€§å‹•è© (extract, parse, identify)
- å›ºå®šçš„schemaæˆ–æ¬„ä½
- åˆ†é¡ã€æ¨™è¨˜ã€æª¢æ¸¬é¡ä»»å‹™
- â¡ï¸ é©åˆ: Rules-based, Few-shot

ğŸ§  **é–‹æ”¾æ€§æ¨ç†ç‰¹å¾µ**ï¼š
- æ¨ç†æ€§å‹•è© (explain, analyze, discuss)
- é–‹æ”¾æ€§å•é¡Œ (why, how, what if)
- éœ€è¦è«–è­‰ã€è©•ä¼°ã€æ¯”è¼ƒ
- å¤šè§’åº¦æ€è€ƒã€å‰µæ„ç™¼æƒ³
- â¡ï¸ é©åˆ: CoT, ReAct

ğŸ¯ **é—œéµåˆ¤æ–·æ¨™æº–**ï¼š
1. è¼¸å‡ºæ˜¯å¦æœ‰å›ºå®šæ ¼å¼ï¼Ÿ
2. æ˜¯å¦éœ€è¦è¤‡é›œæ¨ç†éç¨‹ï¼Ÿ
3. ç­”æ¡ˆæ˜¯å¦æœ‰æ¨™æº–ç­”æ¡ˆï¼Ÿ
4. æ˜¯å¦éœ€è¦å‰µæ„æˆ–å¤šè§’åº¦æ€è€ƒï¼Ÿ
""")