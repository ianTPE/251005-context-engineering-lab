"""
Extended Context Engineering Experiment
=======================================
åŒ…å« Rules-based, Few-shot, CoT (Chain-of-Thought), ReAct çš„å®Œæ•´æ¯”è¼ƒ
plus æ™ºèƒ½é åˆ¤ç³»çµ±é¸æ“‡æœ€å„ªç­–ç•¥
"""

import json
import os
import re
from datetime import datetime
from openai import OpenAI
from typing import Dict, List

# Check for API key
if not os.getenv("OPENAI_API_KEY"):
    print("âŒ ERROR: OPENAI_API_KEY environment variable not set!")
    exit(1)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Test sentences
TESTS = [
    "é€™æ”¯è€³æ©ŸéŸ³è³ªä¸éŒ¯ï¼Œä½†è—ç‰™å¸¸å¸¸æ–·ç·šã€‚",
    "The keyboard feels great, but the battery dies too fast.",
    "ç›¸æ©Ÿç•«è³ªå¾ˆæ£’ï¼Œå¯æ˜¯å¤œæ‹å°ç„¦å¾ˆæ…¢ã€‚",
    "æˆ‘æœ€è¿‘è²·äº†é€™æ¬¾ç„¡ç·šè€³æ©Ÿï¼Œæ•´é«”ä¾†èªªéŸ³è³ªè¡¨ç¾ç›¸ç•¶å‡ºè‰²ï¼Œä½éŸ³æ¸¾åšã€é«˜éŸ³æ¸…æ™°ã€‚ä¸éä½¿ç”¨äº†å…©å€‹ç¦®æ‹œå¾Œç™¼ç¾ï¼Œè—ç‰™é€£ç·šç¶“å¸¸æœƒçªç„¶æ–·æ‰ï¼Œå°¤å…¶æ˜¯åœ¨äººå¤šçš„åœ°æ–¹æ›´æ˜é¡¯ï¼Œéœ€è¦é‡æ–°é…å°æ‰èƒ½ä½¿ç”¨ï¼Œé€™é»çœŸçš„å¾ˆå›°æ“¾ã€‚",
    "The mechanical keyboard I purchased has excellent build quality with a satisfying tactile feedback that makes typing a pleasure. However, I'm quite disappointed with the battery life - it only lasts about 3-4 days with the RGB lighting on, which is far shorter than the advertised 2 weeks. I find myself charging it constantly.",
    "é€™å°ç›¸æ©Ÿçš„ç•«è³ªçœŸçš„æ²’è©±èªªï¼Œæ—¥æ‹çš„ç…§ç‰‡è‰²å½©é®®è±”ã€ç´°ç¯€è±å¯Œï¼Œå®Œå…¨é”åˆ°å°ˆæ¥­æ°´æº–ã€‚ä½†æ˜¯ä¸€åˆ°æ™šä¸Šæˆ–å…‰ç·šä¸è¶³çš„ç’°å¢ƒï¼Œå°ç„¦é€Ÿåº¦å°±è®Šå¾—è¶…ç´šæ…¢ï¼Œå¸¸å¸¸è¦å°å¥½å¹¾æ¬¡æ‰èƒ½æˆåŠŸï¼Œæ‹å¤œæ™¯æˆ–å®¤å…§ç…§ç‰‡æ™‚å¾ˆä¸æ–¹ä¾¿ï¼Œå¸Œæœ›æœªä¾†éŸŒé«”æ›´æ–°èƒ½æ”¹å–„é€™å€‹å•é¡Œã€‚",
    "é€™æ¬¾æ™ºæ…§æ‰‹éŒ¶çš„è¢å¹•é¡¯ç¤ºæ•ˆæœå¾ˆæ£’ï¼Œåœ¨é™½å…‰ä¸‹ä¹Ÿèƒ½æ¸…æ¥šçœ‹è¦‹ï¼Œè€Œä¸”é‹å‹•è¿½è¹¤åŠŸèƒ½å¾ˆæº–ç¢ºã€‚å¯æ˜¯çºŒèˆªåŠ›çœŸçš„è®“äººå¤±æœ›ï¼Œå®˜æ–¹èªªå¯ä»¥ç”¨5å¤©ï¼Œä½†å¯¦éš›ä¸Šé–‹å•Ÿæ‰€æœ‰åŠŸèƒ½å¾Œï¼Œå¤§æ¦‚2å¤©å°±è¦å……é›»äº†ã€‚å¦å¤–å……é›»é€Ÿåº¦ä¹Ÿå¾ˆæ…¢ï¼Œè¦å……æ»¿é›»éœ€è¦å°‡è¿‘3å°æ™‚ï¼Œå°æ–¼ç¶“å¸¸å¤–å‡ºçš„äººä¾†èªªå¾ˆä¸æ–¹ä¾¿ã€‚"
]

# ============================================================================
# All Context Strategies
# ============================================================================

def build_rules_based_input(user_sentence):
    """Rules-based strategy"""
    return f"""Task: Extract fields from the sentence.
Return ONLY a JSON object with these exact keys: sentiment, product, issue.

Rules:
- sentiment must be one of: positive, neutral, negative
- If product is not explicit, infer the most likely product noun (e.g., 'headphones', 'keyboard')
- issue should describe the problem mentioned, or be empty string if none
- Return ONLY valid JSON, no comments, no extra text, no markdown code blocks
- Use lowercase English for all field values

Sentence: {user_sentence}"""

def build_few_shot_input(user_sentence):
    """Few-shot strategy"""
    return f"""You are a product review analyzer. Extract sentiment, product, and issue from reviews.

Rules:
- sentiment: must be "positive", "neutral", or "negative"
- product: infer the product type in lowercase English
- issue: describe the problem, or empty string if none
- Return ONLY valid JSON with keys: sentiment, product, issue
- No markdown, no extra text

Examples:

Example 1:
Input: "é€™å°ç­†é›»è¢å¹•å¾ˆäº®ï¼Œä½†æ˜¯æ•£ç†±å¾ˆåµã€‚"
Output: {{"sentiment": "negative", "product": "laptop", "issue": "noisy cooling"}}

Example 2:
Input: "These earbuds are comfortable and the mic is clear."
Output: {{"sentiment": "positive", "product": "earbuds", "issue": ""}}

Example 3:
Input: "The mouse is lightweight but clicks feel mushy."
Output: {{"sentiment": "negative", "product": "mouse", "issue": "mushy clicks"}}

Now analyze this sentence:
Input: "{user_sentence}"
Output:"""

def build_cot_input(user_sentence):
    """Chain-of-Thought strategy"""
    return f"""You are a product review analyzer. Extract sentiment, product, and issue from reviews using step-by-step reasoning.

Task: Analyze the following review and extract sentiment, product, and issue.
Return your final answer as JSON with keys: sentiment, product, issue.

Let me think through this step by step:

1. **Identify the product**: First, I'll identify what product is being reviewed
2. **Analyze sentiment**: Then, I'll determine the overall sentiment by looking at positive/negative language
3. **Extract issues**: Finally, I'll identify any specific problems mentioned

Review to analyze: "{user_sentence}"

Let me work through this:

1. **Product identification**: Looking at the review, I need to identify what product is being discussed...

2. **Sentiment analysis**: I need to weigh the positive and negative aspects mentioned...

3. **Issue extraction**: I need to identify the specific problems mentioned...

Based on my step-by-step analysis, here is my final answer:"""

def build_react_input(user_sentence):
    """ReAct (Reasoning + Acting) strategy"""
    return f"""You are a product review analyzer using ReAct methodology. Use the format: Thought â†’ Action â†’ Observation â†’ Thought â†’ Action â†’ Observation...

Task: Extract sentiment, product, and issue from this review: "{user_sentence}"

Let me use ReAct reasoning:

**Thought 1**: I need to analyze this review systematically. Let me start by identifying the product type.

**Action 1**: Examine the review for product-related keywords and context clues.

**Observation 1**: [Analyze the text for product indicators]

**Thought 2**: Now I should determine the overall sentiment by weighing positive vs negative expressions.

**Action 2**: Identify sentiment-bearing words and phrases, then evaluate the overall tone.

**Observation 2**: [Analyze sentiment indicators in the text]

**Thought 3**: Finally, I need to extract any specific issues or problems mentioned.

**Action 3**: Look for complaint words, problem descriptions, or negative experiences described.

**Observation 3**: [Identify specific issues mentioned]

**Thought 4**: Based on my systematic analysis, I can now provide the structured output.

**Final Answer**: Let me format this as the required JSON:"""

# ============================================================================
# Enhanced Strategy Predictor
# ============================================================================

class ExtendedStrategyPredictor:
    """æ“´å±•çš„ç­–ç•¥é åˆ¤å™¨ï¼Œæ”¯æ´4ç¨®ç­–ç•¥é¸æ“‡"""
    
    def __init__(self):
        self.complexity_weights = {
            'length': 0.15,
            'ambiguity': 0.25,
            'mixed_language': 0.15,
            'technical_terms': 0.15,
            'sentiment_clarity': 0.15,
            'reasoning_complexity': 0.15  # æ–°å¢ï¼šæ¨ç†è¤‡é›œåº¦
        }
        
        # ä¸åŒè¤‡é›œåº¦æ¨¡å¼å°æ‡‰çš„ç­–ç•¥
        self.strategy_thresholds = {
            'rules_based': 0.3,     # æœ€ç°¡å–®
            'few_shot': 0.5,        # ä¸­ç­‰
            'cot': 0.7,             # è¤‡é›œæ¨ç†
            'react': 0.8            # æœ€è¤‡é›œ
        }
        
        self.difficult_patterns = {
            'rules_based': [],  # ç„¡ç‰¹æ®Šæ¨¡å¼
            'few_shot': [
                r'ä½†æ˜¯.*ä¸é.*é‚„æ˜¯',
                r'é›–ç„¶.*å¯æ˜¯.*ç„¶è€Œ', 
                r'æ•´é«”.*(?:ä¸é|ä½†æ˜¯|å¯æ˜¯)',
            ],
            'cot': [
                r'ä¸€æ–¹é¢.*å¦ä¸€æ–¹é¢.*åŒæ™‚',    # éœ€è¦æ¬Šè¡¡å¤šå€‹å› ç´ 
                r'åŸæœ¬.*å¾Œä¾†.*ç¾åœ¨',          # æ™‚é–“åºåˆ—åˆ†æ
                r'è¡¨é¢ä¸Š.*å¯¦éš›ä¸Š.*ç¸½çš„ä¾†èªª',  # æ·±å±¤vsè¡¨å±¤åˆ†æ
            ],
            'react': [
                r'èªªæ˜¯.*ä½†å…¶å¯¦.*ä¸é.*æœ€å¾Œ',  # éœ€è¦å¤šæ­¥æ¨ç†
                r'å‰›é–‹å§‹.*æ…¢æ…¢.*é€æ¼¸.*æœ€çµ‚',  # è¤‡é›œçš„éç¨‹åˆ†æ
                r'ç†è«–ä¸Š.*å¯¦è¸ä¸­.*ç¶“é.*ç™¼ç¾', # éœ€è¦é©—è­‰å’Œè§€å¯Ÿ
            ]
        }
    
    def analyze_reasoning_complexity(self, text: str) -> float:
        """åˆ†ææ¨ç†è¤‡é›œåº¦"""
        # å› æœé—œä¿‚è©
        causal_words = ['å› ç‚º', 'æ‰€ä»¥', 'å› æ­¤', 'because', 'therefore', 'thus']
        causal_count = sum(1 for word in causal_words if word in text)
        
        # å°æ¯”è©
        contrast_words = ['ç›¸æ¯”', 'æ¯”è¼ƒ', 'compared', 'versus', 'against']  
        contrast_count = sum(1 for word in contrast_words if word in text)
        
        # æ™‚é–“åºåˆ—è©
        temporal_words = ['å‰›é–‹å§‹', 'å¾Œä¾†', 'æœ€å¾Œ', 'æœ€çµ‚', 'initially', 'eventually', 'finally']
        temporal_count = sum(1 for word in temporal_words if word in text)
        
        reasoning_score = (causal_count + contrast_count + temporal_count) / 10
        return min(reasoning_score, 1.0)
    
    def analyze_input_complexity(self, text: str) -> Dict[str, float]:
        """æ“´å±•çš„è¤‡é›œåº¦åˆ†æ"""
        features = {}
        
        features['length'] = min(len(text) / 200, 1.0)
        
        ambiguous_words = ['é‚„å¥½', 'ä¸éŒ¯', 'ä¸€èˆ¬', 'decent', 'okay', 'fine', 'æ™®é€š']
        ambiguity_count = sum(1 for word in ambiguous_words if word in text)
        features['ambiguity'] = min(ambiguity_count / 3, 1.0)
        
        has_chinese = bool(re.search(r'[\u4e00-\u9fff]', text))
        has_english = bool(re.search(r'[a-zA-Z]', text))
        features['mixed_language'] = 0.3 if (has_chinese and has_english) else 0.0
        
        technical_patterns = [
            r'\w+(?:è—ç‰™|WiFi|RGB|DPI|Hz|çºŒèˆª|éŸŒé«”)', 
            r'(?:bluetooth|wireless|battery|firmware|latency|resolution)'
        ]
        tech_count = sum(len(re.findall(pattern, text, re.IGNORECASE)) 
                        for pattern in technical_patterns)
        features['technical_terms'] = min(tech_count / 5, 1.0)
        
        transition_words = ['ä½†æ˜¯', 'ä¸é', 'å¯æ˜¯', 'ç„¶è€Œ', 'but', 'however', 'though', 'although']
        transition_count = sum(1 for word in transition_words if word in text)
        features['sentiment_clarity'] = min(transition_count / 2, 1.0)
        
        # æ–°å¢ï¼šæ¨ç†è¤‡é›œåº¦
        features['reasoning_complexity'] = self.analyze_reasoning_complexity(text)
        
        return features
    
    def calculate_complexity_score(self, features: Dict[str, float]) -> float:
        score = sum(features[key] * self.complexity_weights[key] 
                   for key in features if key in self.complexity_weights)
        return min(score, 1.0)
    
    def detect_strategy_patterns(self, text: str) -> Dict[str, List[str]]:
        """æª¢æ¸¬å„ç­–ç•¥çš„ç‰¹å®šæ¨¡å¼"""
        detected = {}
        for strategy, patterns in self.difficult_patterns.items():
            detected[strategy] = []
            for pattern in patterns:
                if re.search(pattern, text):
                    detected[strategy].append(pattern)
        return detected
    
    def predict_strategy(self, text: str) -> Dict:
        """é åˆ¤æœ€ä½³ç­–ç•¥ï¼ˆ4é¸1ï¼‰"""
        features = self.analyze_input_complexity(text)
        complexity_score = self.calculate_complexity_score(features)
        pattern_matches = self.detect_strategy_patterns(text)
        
        # æª¢æŸ¥ç‰¹å®šæ¨¡å¼åŒ¹é…
        for strategy in ['react', 'cot', 'few_shot']:  # å¾æœ€è¤‡é›œé–‹å§‹æª¢æŸ¥
            if pattern_matches[strategy]:
                return {
                    "strategy": strategy,
                    "reason": f"æª¢æ¸¬åˆ°{strategy}æ¨¡å¼: {pattern_matches[strategy][0]}",
                    "confidence": 0.85,
                    "complexity_score": complexity_score,
                    "features": features,
                    "detected_patterns": pattern_matches[strategy]
                }
        
        # åŸºæ–¼è¤‡é›œåº¦åˆ†æ•¸é¸æ“‡
        if complexity_score >= self.strategy_thresholds['react']:
            strategy = "react"
            reason = f"æ¥µé«˜è¤‡é›œåº¦ {complexity_score:.2f} >= {self.strategy_thresholds['react']}"
        elif complexity_score >= self.strategy_thresholds['cot']:
            strategy = "cot"
            reason = f"é«˜è¤‡é›œåº¦ {complexity_score:.2f} >= {self.strategy_thresholds['cot']}"
        elif complexity_score >= self.strategy_thresholds['few_shot']:
            strategy = "few_shot"
            reason = f"ä¸­è¤‡é›œåº¦ {complexity_score:.2f} >= {self.strategy_thresholds['few_shot']}"
        else:
            strategy = "rules_based"
            reason = f"ä½è¤‡é›œåº¦ {complexity_score:.2f} < {self.strategy_thresholds['few_shot']}"
        
        confidence = min(max(complexity_score, 0.6), 0.95)
        
        return {
            "strategy": strategy,
            "reason": reason,
            "confidence": confidence,
            "complexity_score": complexity_score,
            "features": features,
            "detected_patterns": []
        }

# ============================================================================
# Token Usage Estimation
# ============================================================================

TOKEN_ESTIMATES = {
    'rules_based': 120,
    'few_shot': 250,
    'cot': 350,          # CoTéœ€è¦æ›´å¤šæ¨ç†æ–‡å­—
    'react': 450         # ReActæœ€è¤‡é›œï¼Œtokenæœ€å¤š
}

# ============================================================================
# API and Evaluation Functions
# ============================================================================

def call_responses_api(input_text, model="gpt-5"):
    try:
        response = client.responses.create(
            model=model,
            input=input_text
        )
        return response.output_text
    except AttributeError as e:
        return f"ERROR: Your OpenAI SDK version doesn't support responses.create(). Please upgrade: pip install --upgrade openai"
    except Exception as e:
        return f"ERROR: {str(e)}"

def clean_json_output(text):
    # Clean CoT and ReAct reasoning text, keep only JSON
    if "Final Answer" in text:
        parts = text.split("Final Answer")
        text = parts[-1] if parts else text
    
    # Extract JSON from code blocks
    if "```" in text:
        lines = text.split("\n")
        json_lines = []
        in_code_block = False
        for line in lines:
            if line.strip().startswith("```"):
                in_code_block = not in_code_block
                continue
            if in_code_block:
                json_lines.append(line)
        text = "\n".join(json_lines)
    
    # Try to find JSON pattern
    json_match = re.search(r'\{[^{}]*"sentiment"[^{}]*\}', text)
    if json_match:
        text = json_match.group()
    
    return text.strip()

def score_json(output_text):
    try:
        cleaned = clean_json_output(output_text)
        obj = json.loads(cleaned)
        
        required_keys = {"sentiment", "product", "issue"}
        keys_ok = set(obj.keys()) == required_keys
        
        valid_sentiments = {"positive", "neutral", "negative"}
        sentiment_ok = obj.get("sentiment", "").lower() in valid_sentiments
        
        product_ok = isinstance(obj.get("product"), str) and len(obj.get("product", "")) > 0
        issue_ok = "issue" in obj and isinstance(obj.get("issue"), str)
        
        if keys_ok and sentiment_ok and product_ok and issue_ok:
            return 1, obj, None
        else:
            errors = []
            if not keys_ok: errors.append(f"wrong_keys: {set(obj.keys())}")
            if not sentiment_ok: errors.append(f"invalid_sentiment: {obj.get('sentiment')}")
            if not product_ok: errors.append("empty_or_invalid_product")
            if not issue_ok: errors.append("missing_or_invalid_issue")
            return 0, obj, ", ".join(errors)
            
    except json.JSONDecodeError as e:
        return 0, None, f"JSON parse error: {str(e)}"
    except Exception as e:
        return 0, None, f"Unexpected error: {str(e)}"

# ============================================================================
# Evaluation Functions
# ============================================================================

def evaluate_single_strategy(strategy_name, input_builder, verbose=True):
    """è©•ä¼°å–®ä¸€ç­–ç•¥"""
    if verbose:
        print(f"\n{'='*70}")
        print(f"  {strategy_name.upper()}")
        print(f"{'='*70}\n")
    
    results = []
    total_score = 0
    total_tokens = 0
    
    for i, test_sentence in enumerate(TESTS, 1):
        input_text = input_builder(test_sentence)
        estimated_tokens = TOKEN_ESTIMATES.get(strategy_name.lower().replace('-', '_').replace(' ', '_'), 200)
        total_tokens += estimated_tokens
        
        output = call_responses_api(input_text)
        
        if output.startswith("ERROR: Your OpenAI SDK"):
            if verbose:
                print(f"\nâš ï¸  {output}")
            return None
        
        score, parsed, error = score_json(output)
        total_score += score
        
        result = {
            "test_id": i,
            "input": test_sentence,
            "output": output,
            "parsed": parsed,
            "score": score,
            "error": error,
            "estimated_tokens": estimated_tokens
        }
        results.append(result)
        
        if verbose:
            print(f"Test {i}: {test_sentence[:50]}{'...' if len(test_sentence) > 50 else ''}")
            print(f"Score: {score}/1 {f'({error})' if error else 'âœ…'}")
            print()
    
    success_rate = total_score / len(TESTS)
    if verbose:
        print(f"Results: {total_score}/{len(TESTS)} ({success_rate*100:.1f}%)")
        print(f"Estimated tokens: ~{total_tokens}")
    
    return {
        "strategy": strategy_name,
        "total_score": total_score,
        "success_rate": success_rate,
        "total_tokens": total_tokens,
        "results": results
    }

def evaluate_smart_selection(predictor, verbose=True):
    """è©•ä¼°æ™ºèƒ½é¸æ“‡ç­–ç•¥"""
    if verbose:
        print(f"\n{'='*70}")
        print(f"  SMART STRATEGY SELECTION")
        print(f"{'='*70}\n")
    
    builders = {
        'rules_based': build_rules_based_input,
        'few_shot': build_few_shot_input,
        'cot': build_cot_input,
        'react': build_react_input
    }
    
    results = []
    total_score = 0
    total_tokens = 0
    strategy_counts = {strategy: 0 for strategy in builders.keys()}
    
    for i, test_sentence in enumerate(TESTS, 1):
        prediction = predictor.predict_strategy(test_sentence)
        selected_strategy = prediction["strategy"]
        strategy_counts[selected_strategy] += 1
        
        input_text = builders[selected_strategy](test_sentence)
        estimated_tokens = TOKEN_ESTIMATES.get(selected_strategy, 200)
        total_tokens += estimated_tokens
        
        output = call_responses_api(input_text)
        
        if output.startswith("ERROR: Your OpenAI SDK"):
            if verbose:
                print(f"\nâš ï¸  {output}")
            return None
        
        score, parsed, error = score_json(output)
        total_score += score
        
        result = {
            "test_id": i,
            "input": test_sentence,
            "prediction": prediction,
            "output": output,
            "parsed": parsed,
            "score": score,
            "error": error,
            "estimated_tokens": estimated_tokens
        }
        results.append(result)
        
        if verbose:
            print(f"Test {i}: {test_sentence[:50]}{'...' if len(test_sentence) > 50 else ''}")
            print(f"ğŸ¯ Selected: {selected_strategy} (confidence: {prediction['confidence']:.2f})")
            print(f"ğŸ’¡ Reason: {prediction['reason']}")
            print(f"Score: {score}/1 {f'({error})' if error else 'âœ…'}")
            print()
    
    success_rate = total_score / len(TESTS)
    if verbose:
        print(f"{'='*70}")
        print(f"Results: {total_score}/{len(TESTS)} ({success_rate*100:.1f}%)")
        print(f"Strategy distribution:")
        for strategy, count in strategy_counts.items():
            print(f"  {strategy}: {count}/{len(TESTS)} ({count/len(TESTS)*100:.1f}%)")
        print(f"Total estimated tokens: ~{total_tokens}")
    
    return {
        "strategy": "Smart Selection",
        "total_score": total_score,
        "success_rate": success_rate,
        "total_tokens": total_tokens,
        "strategy_counts": strategy_counts,
        "results": results
    }

def run_extended_experiment():
    """é‹è¡Œæ“´å±•å¯¦é©—"""
    print("\n" + "="*80)
    print("  EXTENDED CONTEXT ENGINEERING EXPERIMENT")
    print("  Rules-based | Few-shot | CoT | ReAct + Smart Selection")
    print("="*80)
    
    # è©•ä¼°æ‰€æœ‰ç­–ç•¥
    strategies_to_test = [
        ("Rules-based", build_rules_based_input),
        ("Few-shot", build_few_shot_input), 
        ("CoT (Chain-of-Thought)", build_cot_input),
        ("ReAct (Reasoning + Acting)", build_react_input)
    ]
    
    all_results = {}
    
    # æ¸¬è©¦å„å€‹å›ºå®šç­–ç•¥
    for strategy_name, builder in strategies_to_test:
        result = evaluate_single_strategy(strategy_name, builder)
        if result is None:
            return
        all_results[strategy_name] = result
    
    # æ¸¬è©¦æ™ºèƒ½é¸æ“‡
    predictor = ExtendedStrategyPredictor()
    smart_result = evaluate_smart_selection(predictor)
    if smart_result is None:
        return
    all_results["Smart Selection"] = smart_result
    
    # æ¯”è¼ƒçµæœ
    print(f"\n{'='*80}")
    print("  COMPREHENSIVE COMPARISON")
    print("="*80)
    print(f"{'Strategy':<25} {'Success Rate':<12} {'Est. Tokens':<12} {'Efficiency':<10}")
    print("-" * 80)
    
    for strategy_name, result in all_results.items():
        efficiency = result["success_rate"] / (result["total_tokens"] / 1000)  # æˆåŠŸç‡/åƒtoken
        print(f"{strategy_name:<25} {result['success_rate']*100:>8.1f}%    {result['total_tokens']:>8d}      {efficiency:>6.2f}")
    
    # æ‰¾å‡ºæœ€ä½³ç­–ç•¥
    best_by_accuracy = max(all_results.items(), key=lambda x: x[1]["success_rate"])
    best_by_efficiency = max(all_results.items(), key=lambda x: x[1]["success_rate"] / (x[1]["total_tokens"] / 1000))
    most_economical = min(all_results.items(), key=lambda x: x[1]["total_tokens"])
    
    print(f"\nğŸ† Best by accuracy: {best_by_accuracy[0]} ({best_by_accuracy[1]['success_rate']*100:.1f}%)")
    print(f"âš¡ Best efficiency: {best_by_efficiency[0]}")
    print(f"ğŸ’° Most economical: {most_economical[0]} (~{most_economical[1]['total_tokens']} tokens)")
    
    # ä¿å­˜çµæœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"extended_context_experiment_{timestamp}.json"
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump({
            "timestamp": timestamp,
            "experiment_type": "Extended Context Engineering with CoT, ReAct",
            "results": {k: v for k, v in all_results.items()},
            "summary": {
                "best_accuracy": best_by_accuracy[0],
                "best_efficiency": best_by_efficiency[0],
                "most_economical": most_economical[0]
            }
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“Š Detailed results saved to: {output_file}")

if __name__ == "__main__":
    try:
        run_extended_experiment()
        
        print("\n" + "="*80)
        print("  EXPERIMENT INSIGHTS")
        print("="*80)
        print("ğŸ§  CoT: Best for complex reasoning tasks")
        print("ğŸ”„ ReAct: Best for multi-step analysis")
        print("ğŸ“Š Few-shot: Reliable baseline with examples")
        print("ğŸ“‹ Rules-based: Most economical for simple tasks")
        print("ğŸ¯ Smart Selection: Optimal balance of all approaches")
        
    except Exception as e:
        print(f"\nâŒ Experiment failed: {str(e)}")
        import traceback
        traceback.print_exc()