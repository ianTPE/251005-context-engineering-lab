"""
Context Engineering Experiment - Extended Test Cases
====================================================
Êì¥Â±ïÊ∏¨Ë©¶Ê°à‰æãÔºåÂåÖÂê´ÂêÑÁ®ÆÊåëÊà∞ÊÄßÂ†¥ÊôØÔºö
- Positive Ë©ïË´ñ
- Neutral Ë©ïË´ñ
- Ê•µÈï∑Ë©ïË´ñÔºà300+ Â≠óÔºâ
- Áü≠Ë©ïË´ñ
- Ê≤íÊúâÊòéÁ¢∫ÂïèÈ°å
- Â§öÂÄãÁî¢ÂìÅ
- Ë´∑Âà∫ÊÄßË©ïË´ñ
"""

import json
import os
from datetime import datetime
from openai import OpenAI

# Check for API key
if not os.getenv("OPENAI_API_KEY"):
    print("‚ùå ERROR: OPENAI_API_KEY environment variable not set!")
    print("\nPlease set your OpenAI API key:")
    print("  Windows (PowerShell): $env:OPENAI_API_KEY='your-key-here'")
    exit(1)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Extended test cases - 12 cases covering various scenarios
TESTS = [
    # 1. SHORT POSITIVE (Áü≠Ë©ïÔºåÁ¥îÊ≠£Èù¢)
    {
        "text": "ÈÄôÂÄãËóçÁâôÂñáÂè≠Èü≥Ë≥™Ë∂ÖÊ£íÔºåcpÂÄºÂæàÈ´òÔºÅ",
        "expected_sentiment": "positive",
        "expected_product": "speaker",
        "category": "Áü≠Ë©ï-Ê≠£Èù¢"
    },
    
    # 2. SHORT NEUTRAL (Áü≠Ë©ïÔºå‰∏≠ÊÄßÊèèËø∞)
    {
        "text": "This USB hub has 4 ports and works as expected.",
        "expected_sentiment": "neutral",
        "expected_product": "usb hub",
        "category": "Áü≠Ë©ï-‰∏≠ÊÄß"
    },
    
    # 3. POSITIVE - ÂÆåÂÖ®ÊªøÊÑèÁöÑË©ïË´ñ
    {
        "text": "ÊàëÁî®ÈÄôÊ¨æÁ≠ÜË®òÂûãÈõªËÖ¶Â∑≤Á∂ìÂçäÂπ¥‰∫ÜÔºåÊï¥È´îÈ´îÈ©óÈùûÂ∏∏Ê£íÔºÅÊïàËÉΩÂº∑Â§ßÂèØ‰ª•ÂêåÊôÇÈñãÂæàÂ§öÁ®ãÂºèÔºåÊï£ÁÜ±Á≥ªÁµ±Ë®≠Ë®àÂæóÂæàÂ•ΩÂç≥‰ΩøÈï∑ÊôÇÈñì‰ΩøÁî®‰πü‰∏çÊúÉÈÅéÁÜ±ÔºåÈçµÁõ§ÊâãÊÑüËàíÈÅ©ÊâìÂ≠óÂæàÊµÅÊö¢ÔºåËû¢ÂπïÈ°ØÁ§∫Ê∏ÖÊô∞Ëâ≤ÂΩ©Ê∫ñÁ¢∫ÔºåÈõªÊ±†Á∫åËà™Âäõ‰πüÂæà‰∏çÈåØÔºåÂá∫ÈñÄÂ∑•‰Ωú‰∏ÄÊï¥Â§©ÈÉΩÊ≤íÂïèÈ°å„ÄÇÂÆ¢ÊúçÊÖãÂ∫¶‰πüÂæàÂ•ΩÔºåÊúâÂïèÈ°åÈ¶¨‰∏äËß£Ê±∫„ÄÇÂº∑ÁÉàÊé®Ëñ¶Áµ¶ÈúÄË¶ÅÈ´òÊïàËÉΩÁ≠ÜÈõªÁöÑÊúãÂèãÔºÅ",
        "expected_sentiment": "positive",
        "expected_product": "laptop",
        "category": "Ê≠£Èù¢-ÁÑ°ÂïèÈ°å"
    },
    
    # 4. NEUTRAL - ÂÆ¢ËßÄÊèèËø∞ÔºåÁÑ°ÊòéÈ°ØÊÉÖÊÑüÂÇæÂêë
    {
        "text": "I purchased this external hard drive for backup purposes. It has 2TB storage capacity, USB 3.0 connectivity, and comes with backup software. The transfer speed is around 120MB/s, which is within the standard range for this type of device. The build quality is plastic but feels solid. It's been working for three months without any issues. Price is comparable to similar products in the market.",
        "expected_sentiment": "neutral",
        "expected_product": "external hard drive",
        "category": "‰∏≠ÊÄß-ÂÆ¢ËßÄÊèèËø∞"
    },
    
    # 5. VERY LONG - Ê•µÈï∑Ë©ïË´ñÔºà300+ Â≠óÔºâÔºåÊ∑∑ÂêàÊÉÖÊÑü
    {
        "text": "ÊàëÂú®‰∏âÂÄãÊúàÂâçË≥ºË≤∑‰∫ÜÈÄôÊ¨æÊóóËâ¶Á¥öÊô∫ÊÖßÂûãÊâãÊ©üÔºåÂÉπÊ†ºÈõñÁÑ∂‰∏ç‰æøÂÆú‰ΩÜÊàëË¶∫ÂæóÈÇÑÁÆóÂêàÁêÜÔºåÁï¢Á´üË¶èÊ†ºÁúüÁöÑÂæàÈ†Ç„ÄÇÂÖàË™™ÂÑ™ÈªûÔºåËû¢ÂπïÁúüÁöÑÊòØÊàëÁî®ÈÅéÊúÄÊ£íÁöÑÔºå6.7ÂêãAMOLEDÈù¢ÊùøÔºå120HzÊõ¥Êñ∞ÁéáÔºåÈ°èËâ≤ÈÆÆË±îÂèà‰∏çÊúÉÈÅéÊñºÊøÉËâ∑ÔºåÁúãÂΩ±ÁâáÂíåÁé©ÈÅäÊà≤ÁöÑÈ´îÈ©óÈÉΩÈùûÂ∏∏Â•Ω„ÄÇÊãçÁÖßÂäüËÉΩ‰πüÂæàÂº∑Â§ßÔºå‰∏ªÈè°È†≠5000Ëê¨Áï´Á¥†ÔºåÊãçÂá∫‰æÜÁöÑÁÖßÁâáÁ¥∞ÁØÄË±êÂØåÔºåËâ≤ÂΩ©ÈÇÑÂéüÂ∫¶È´òÔºåÂ§úÊãçÊ®°Âºè‰πüËôïÁêÜÂæóÂæàÂ•ΩÔºåÈõúË®äÊéßÂà∂ÂæóÂÆú„ÄÇËôïÁêÜÂô®ÊòØÊúÄÊñ∞ÁöÑÊóóËâ¶Êô∂ÁâáÔºåÊïàËÉΩÁ¢∫ÂØ¶ÂæàÂº∑ÔºåÈñã‰ªª‰ΩïappÈÉΩÂæàÊµÅÊö¢ÔºåÂ§öÂ∑•ËôïÁêÜ‰πü‰∏çÊúÉÂç°È†ì„ÄÇ‰∏çÈÅé‰ΩøÁî®‰∏ÄÊÆµÊôÇÈñìÂæå‰πüÁôºÁèæ‰∫Ü‰∏Ä‰∫õÂïèÈ°å„ÄÇÈ¶ñÂÖàÊòØÁôºÁÜ±ÂïèÈ°åÔºåÁé©ÈÅäÊà≤ÊàñÊãçÊîùÂΩ±ÁâáË∂ÖÈÅé30ÂàÜÈêòÔºåÊâãÊ©üËÉåÈù¢Â∞±ÊúÉËÆäÂæóÂæàÁáôÔºåÈõñÁÑ∂‰∏çËá≥ÊñºÁáôÊâã‰ΩÜÈÇÑÊòØËÆì‰∫∫ÊúâÈªûÊìîÂøÉ„ÄÇÂÖ∂Ê¨°ÊòØÈõªÊ±†Á∫åËà™ÔºåÈõñÁÑ∂ÂÆòÊñπÊ®ôÊ¶ú5000mAhÂ§ßÈõªÊ±†Ôºå‰ΩÜÂØ¶Èöõ‰ΩøÁî®‰∏ã‰æÜÔºåÂ¶ÇÊûúÂ∏∏ÈñãÂïü5GÂíåÈ´òÊõ¥Êñ∞ÁéáËû¢ÂπïÔºåÂ§ßÊ¶ÇÂà∞‰∏ãÂçà3-4ÈªûÂ∞±Ë¶ÅÂÖÖÈõª‰∫ÜÔºåË∑üÈ†êÊúüÊúâËêΩÂ∑Æ„ÄÇÂè¶Â§ñÁ≥ªÁµ±ÁöÑUIË®≠Ë®àÊàëÂÄã‰∫∫Ë¶∫Âæó‰∏çÂ§†Áõ¥Ë¶∫ÔºåÊúâ‰∫õÂäüËÉΩËóèÂæóÂæàÊ∑±Ë¶ÅÁøªÂ•ΩÂπæÂ±§ÈÅ∏ÂñÆÊâçÊâæÂæóÂà∞ÔºåÈÄôÈªûÂ∏åÊúõ‰πãÂæåËªüÈ´îÊõ¥Êñ∞ËÉΩÊîπÂñÑ„ÄÇÊúÄÂæåÊòØÂÉπÊ†ºÔºåÈõñÁÑ∂Ë¶èÊ†ºÂæàÂ•ΩÔºå‰ΩÜÈÄôÂÄãÂÉπ‰ΩçÂ∑≤Á∂ìÂèØ‰ª•Ë≤∑Âà∞ÂÖ∂‰ªñÂìÅÁâåÁöÑÈ†ÇË¶èÊ©üÁ®ÆÔºåÊâÄ‰ª•ÊÄßÂÉπÊØîÂèØËÉΩ‰∏çÊòØÊúÄÈ´òÁöÑÈÅ∏Êìá„ÄÇÊï¥È´î‰æÜË™™ÊòØÊîØÂ•ΩÊâãÊ©üÔºå‰ΩÜ‰∏çÊòØÂÆåÁæéÔºåÂ¶ÇÊûú‰Ω†ÈáçË¶ñÊïàËÉΩÂíåËû¢ÂπïÂìÅË≥™ÔºåÂèØ‰ª•ËÄÉÊÖÆÔºå‰ΩÜÂ¶ÇÊûúÂú®ÊÑèÁ∫åËà™ÂíåÊ∫´ÊéßÔºåÂèØËÉΩË¶Å‰∏âÊÄù„ÄÇ",
        "expected_sentiment": "neutral",  # Êàñ negativeÔºàÂõ†ÁÇ∫ÂïèÈ°åËºÉÂ§öÔºâ
        "expected_product": "smartphone",
        "category": "Ê•µÈï∑-Ê∑∑ÂêàÊÉÖÊÑü"
    },
    
    # 6. NO CLEAR ISSUE - Ë≤†Èù¢ÊÉÖÁ∑í‰ΩÜÊ≤íÊúâÊòéÁ¢∫ÂïèÈ°å
    {
        "text": "Ë≤∑‰∫ÜÈÄôÂÄãË°åÂãïÈõªÊ∫êË¶∫ÂæóÊúâÈªûÂæåÊÇîÔºåÈõñÁÑ∂Ë™™‰∏ç‰∏ä‰æÜÂì™Ë£°‰∏çÂ•ΩÔºå‰ΩÜÂ∞±ÊòØÊÑüË¶∫‰∏çÂ§™Â∞çÂãÅÔºåÂèØËÉΩÊòØÊàëÊúüÊúõÂ§™È´ò‰∫ÜÂêßÔºåÊï¥È´î‰æÜË™™Â∞±ÊòØÊôÆÈÄöÔºåÊ≤íÊúâÊÉ≥ÂÉè‰∏≠ÈÇ£È∫ºÂ•ΩÁî®Ôºå‰ΩÜ‰πüÈÇÑËÉΩÁî®Âï¶„ÄÇ",
        "expected_sentiment": "negative",
        "expected_product": "power bank",
        "category": "ÈÇäÁïå-Ê®°Á≥äÂïèÈ°å"
    },
    
    # 7. MULTIPLE PRODUCTS - Â§öÂÄãÁî¢ÂìÅÁöÑË©ïË´ñ
    {
        "text": "I bought a complete home office setup including a monitor, keyboard, and mouse. The 27-inch monitor has great color accuracy and the stand is adjustable. The mechanical keyboard is satisfying to type on. However, the wireless mouse is disappointing - it's uncomfortable for long use and the battery drains quickly. Overall, two out of three products are excellent.",
        "expected_sentiment": "neutral",  # Êï¥È´îÊ∑∑Âêà
        "expected_product": "office setup",  # Êàñ mouseÔºà‰∏ªË¶ÅÂïèÈ°åÔºâ
        "category": "ÈÇäÁïå-Â§öÁî¢ÂìÅ"
    },
    
    # 8. SARCASTIC - Ë´∑Âà∫ÊÄßË©ïË´ñ
    {
        "text": "ÂìáÔºåÈÄôÂÄãÂÖÖÈõªÁ∑öÁúüÊòØÂ§™„ÄåËÄêÁî®„Äç‰∫ÜÔºåÊâçÁî®‰∏âÂÄãÊúàÂ∞±Êñ∑ÊéâÔºåÂìÅË≥™ÁúüÊòØ„ÄåÂÑ™ËâØ„ÄçÔºÅÂÆ¢ÊúçÈÇÑË™™ÈÄôÊòØÊ≠£Â∏∏‰ΩøÁî®ÊêçËÄóÔºåÁúüÊòØÂ§™„ÄåË≤ºÂøÉ„Äç‰∫Ü„ÄÇÂº∑ÁÉà„ÄåÊé®Ëñ¶„ÄçÁµ¶ÂñúÊ≠°ÂÆöÊúüË≤∑ÂÖÖÈõªÁ∑öÁöÑÊúãÂèãÔºÅ",
        "expected_sentiment": "negative",
        "expected_product": "charging cable",
        "category": "ÈÇäÁïå-Ë´∑Âà∫"
    },
    
    # 9. POSITIVE with minor mention - Ê≠£Èù¢ÁÇ∫‰∏ªÔºåËºïÂæÆÊèêÂèäÁº∫Èªû
    {
        "text": "This noise-cancelling headphone is absolutely fantastic! The sound quality is crystal clear with deep bass and crisp highs. The noise cancellation works like magic - I can focus completely in noisy environments. Battery lasts for 30+ hours, which is incredible. The only minor thing is the carrying case could be a bit more compact, but that's really nitpicking. Highly recommended!",
        "expected_sentiment": "positive",
        "expected_product": "headphones",
        "category": "Ê≠£Èù¢-ÂæÆÂ∞èÁº∫Èªû"
    },
    
    # 10. NEGATIVE DISGUISED AS POSITIVE - Ë°®Èù¢Ê≠£Èù¢ÂØ¶ÂâáË≤†Èù¢
    {
        "text": "ÈÄôÂè∞Á©∫Ê∞£Ê∏ÖÊ∑®Ê©üÁöÑÂ§ñËßÄË®≠Ë®àÂæàÊºÇ‰∫ÆÔºåÊì∫Âú®ÂÆ¢Âª≥ÂæàÂ•ΩÁúãÔºåËÄå‰∏îÂæàÂÆâÈùúÔºåÈñãËëóÈÉΩ‰∏çÁü•ÈÅìÊúâÊ≤íÊúâÂú®ÈÅã‰Ωú„ÄÇÂÉπÊ†ºÈõñÁÑ∂Ë≤¥‰ΩÜÊÉ≥Ë™™‰∏ÄÂàÜÈå¢‰∏ÄÂàÜË≤®Â∞±Ë≤∑‰∫Ü„ÄÇÁµêÊûúÁî®‰∫ÜÂÖ©ÂÄãÊúàÔºåÂÆåÂÖ®ÊÑüË¶∫‰∏çÂà∞Á©∫Ê∞£ÊúâËÆä‰πæÊ∑®ÔºåÈÅéÊïèÁóáÁãÄ‰∏ÄÊ®£Âö¥ÈáçÔºåÊèõ‰∫ÜÂÖ©Ê¨°ÊøæÁ∂≤‰πüÊ≤íÊîπÂñÑ„ÄÇÂèØËÉΩÂè™ÈÅ©ÂêàÁï∂Ë£ùÈ£æÂìÅÁî®Âêß„ÄÇ",
        "expected_sentiment": "negative",
        "expected_product": "air purifier",
        "category": "ÈÇäÁïå-Ë°®Èù¢Ê≠£Èù¢"
    },
    
    # 11. NEUTRAL with technical details - Á¥îÊäÄË°ìË¶èÊ†ºÊèèËø∞
    {
        "text": "Purchased this router for home use. Specifications: WiFi 6 (802.11ax), dual-band 2.4GHz/5GHz, maximum speed 3000Mbps, 4 Gigabit LAN ports, WPA3 security. Setup took approximately 15 minutes using the mobile app. Coverage area is adequate for a 1500 sq ft apartment. Firmware version 1.2.3 as of purchase date.",
        "expected_sentiment": "neutral",
        "expected_product": "router",
        "category": "‰∏≠ÊÄß-ÊäÄË°ìË¶èÊ†º"
    },
    
    # 12. EXTREME NEGATIVE - Ê•µÂ∫¶Ë≤†Èù¢ÔºåÂ§öÈáçÂö¥ÈáçÂïèÈ°å
    {
        "text": "ÈÄôÁµïÂ∞çÊòØÊàëË≤∑ÈÅéÊúÄÁ≥üÁ≥ïÁöÑÂπ≥ÊùøÈõªËÖ¶ÔºÅÊî∂Âà∞Ë≤®Á¨¨‰∏ÄÂ§©Ëû¢ÂπïÂ∞±Êúâ‰∫ÆÈªûÔºåËß∏ÊéßÁ∂ìÂ∏∏Â§±ÈùàË¶ÅÈªûÂ•ΩÂπæÊ¨°ÊâçÊúâÂèçÊáâÔºåÁ≥ªÁµ±Ë∂ÖÁ¥öÂç°È†ìÈñãÂÄãÁ∂≤È†ÅÈÉΩË¶ÅÁ≠âÂçäÂ§©ÔºåÈõªÊ±†Êõ¥ÊòØÁ¨ëË©±ÔºåÂÖÖÊªøÈõªÂè™ËÉΩÁî®2Â∞èÊôÇÂ∞±Ê≤íÈõª‰∫ÜÔºåËÄå‰∏îÂÖÖÈõªÊôÇÊúÉÁôºÁáôÂà∞Ê†πÊú¨‰∏çÊï¢Á¢∞„ÄÇÂÆ¢ÊúçÊÖãÂ∫¶Ë∂ÖÂ∑ÆÔºåË™™ÈÄô‰∫õÈÉΩÊòØÊ≠£Â∏∏ÁèæË±°‰∏çÁµ¶ÈÄÄÊèõË≤®„ÄÇËä±‰∫Ü‰∏ÄËê¨Â§öÂ°äË≤∑ÂÄãÂûÉÂúæÔºåÊ†πÊú¨Â∞±ÊòØË©êÈ®ôÔºÅÂçÉËê¨‰∏çË¶ÅË≤∑ÔºåÈô§Èùû‰Ω†ÊÉ≥ÊâæÁΩ™ÂèóÔºÅ",
        "expected_sentiment": "negative",
        "expected_product": "tablet",
        "category": "Ê•µË≤†Èù¢-Â§öÂïèÈ°å"
    }
]

# Base system message
SYS_BASE = "You are a helpful assistant that extracts structured information from product reviews."

# ============================================================================
# Context Definitions
# ============================================================================

def build_context_a_input(user_sentence):
    """Context A: Baseline"""
    return f"""Extract sentiment (positive/neutral/negative), product, and issue from this sentence.
Return as JSON.

Sentence: {user_sentence}"""


def build_context_b_input(user_sentence):
    """Context B: Rules-based"""
    return f"""Task: Extract fields from the sentence.
Return ONLY a JSON object with these exact keys: sentiment, product, issue.

Rules:
- sentiment must be one of: positive, neutral, negative
- For positive reviews with no real issues, issue should be empty string
- For sarcastic reviews, focus on the actual negative meaning
- If product is not explicit, infer the most likely product noun
- issue should describe the problem mentioned, or be empty string if none
- Return ONLY valid JSON, no comments, no extra text, no markdown code blocks
- Use lowercase English for all field values

Sentence: {user_sentence}"""


def build_context_c_input(user_sentence):
    """Context C: Few-shot with diverse examples"""
    return f"""You are a product review analyzer. Extract sentiment, product, and issue from reviews.

Rules:
- sentiment: must be "positive", "neutral", or "negative"
- product: infer the product type in lowercase English
- issue: describe the problem, or empty string if none
- Return ONLY valid JSON with keys: sentiment, product, issue
- No markdown, no extra text

Examples:

Example 1 (Positive review):
Input: "This laptop is amazing! Fast, great battery life, and the screen is beautiful."
Output: {{"sentiment": "positive", "product": "laptop", "issue": ""}}

Example 2 (Negative with issue):
Input: "ÈÄôÂè∞Âç∞Ë°®Ê©üÂ∏∏Â∏∏Âç°Á¥ôÔºåËÄå‰∏îÂ¢®Ê∞¥ÂæàÂø´Â∞±Áî®ÂÆå‰∫Ü„ÄÇ"
Output: {{"sentiment": "negative", "product": "printer", "issue": "frequent paper jams and fast ink consumption"}}

Example 3 (Neutral description):
Input: "The USB drive has 64GB capacity and USB 3.0 interface."
Output: {{"sentiment": "neutral", "product": "usb drive", "issue": ""}}

Example 4 (Sarcastic/Negative):
Input: "Great quality! Broke after one week. Totally worth the money!"
Output: {{"sentiment": "negative", "product": "product", "issue": "broke after one week"}}

Now analyze this sentence:
Input: "{user_sentence}"
Output:"""


# ============================================================================
# API Calling Function
# ============================================================================

def call_responses_api(input_text, model="gpt-5"):
    """Call Responses API with GPT-5"""
    try:
        response = client.responses.create(
            model=model,
            input=input_text
        )
        return response.output_text
    except AttributeError as e:
        return f"ERROR: Your OpenAI SDK version doesn't support responses.create()"
    except Exception as e:
        return f"ERROR: {str(e)}"


# ============================================================================
# Scoring and Evaluation
# ============================================================================

def clean_json_output(text):
    """Extract JSON from text"""
    if "```" in text:
        lines = text.split("\n")
        json_lines = []
        in_code_block = False
        for line in lines:
            if line.strip().startswith("```"):
                in_code_block = not in_code_block
                continue
            if in_code_block:
                json_lines.append(line)
        text = "\n".join(json_lines)
    return text.strip()


def score_json(output_text, expected_sentiment=None):
    """Score output with optional expected sentiment check"""
    try:
        cleaned = clean_json_output(output_text)
        obj = json.loads(cleaned)
        
        required_keys = {"sentiment", "product", "issue"}
        keys_ok = set(obj.keys()) == required_keys
        
        valid_sentiments = {"positive", "neutral", "negative"}
        sentiment_ok = obj.get("sentiment", "").lower() in valid_sentiments
        
        product_ok = isinstance(obj.get("product"), str) and len(obj.get("product", "")) > 0
        issue_ok = "issue" in obj and isinstance(obj.get("issue"), str)
        
        # Check if sentiment matches expected (if provided)
        sentiment_match = True
        if expected_sentiment:
            sentiment_match = obj.get("sentiment", "").lower() == expected_sentiment.lower()
        
        if keys_ok and sentiment_ok and product_ok and issue_ok:
            return 1, obj, None, sentiment_match
        else:
            errors = []
            if not keys_ok: errors.append(f"wrong_keys: {set(obj.keys())}")
            if not sentiment_ok: errors.append(f"invalid_sentiment: {obj.get('sentiment')}")
            if not product_ok: errors.append("empty_or_invalid_product")
            if not issue_ok: errors.append("missing_or_invalid_issue")
            return 0, obj, ", ".join(errors), sentiment_match
            
    except json.JSONDecodeError as e:
        return 0, None, f"JSON parse error: {str(e)}", False
    except Exception as e:
        return 0, None, f"Unexpected error: {str(e)}", False


def eval_context(tag, input_builder, verbose=True):
    """Evaluate a context strategy"""
    if verbose:
        print(f"\n{'='*80}")
        print(f"  {tag}")
        print(f"{'='*80}\n")
    
    results = []
    total_score = 0
    sentiment_correct = 0
    
    for i, test_case in enumerate(TESTS, 1):
        test_text = test_case["text"]
        expected_sentiment = test_case.get("expected_sentiment")
        category = test_case.get("category", "")
        
        # Build input
        input_text = input_builder(test_text)
        
        # Call API
        output = call_responses_api(input_text)
        
        # Score output
        score, parsed, error, sentiment_match = score_json(output, expected_sentiment)
        total_score += score
        if sentiment_match:
            sentiment_correct += 1
        
        # Store result
        result = {
            "test_id": i,
            "category": category,
            "input": test_text[:80] + "..." if len(test_text) > 80 else test_text,
            "output": output,
            "parsed": parsed,
            "score": score,
            "error": error,
            "expected_sentiment": expected_sentiment,
            "sentiment_match": sentiment_match
        }
        results.append(result)
        
        # Print if verbose
        if verbose:
            print(f"Test {i} [{category}]:")
            print(f"Input: {test_text[:80]}{'...' if len(test_text) > 80 else ''}")
            print(f"Output: {output}")
            print(f"Parsed: {json.dumps(parsed, ensure_ascii=False) if parsed else 'FAILED'}")
            sentiment_indicator = "‚úì" if sentiment_match else f"‚úó (expected: {expected_sentiment})"
            print(f"Score: {score}/1 {f'({error})' if error else '‚úì'} | Sentiment: {sentiment_indicator}")
            print()
    
    if verbose:
        print(f"[{tag}] Schema Score: {total_score}/{len(TESTS)}")
        print(f"[{tag}] Sentiment Accuracy: {sentiment_correct}/{len(TESTS)} ({sentiment_correct/len(TESTS)*100:.1f}%)")
        print(f"[{tag}] Combined Success Rate: {(total_score/len(TESTS)*0.5 + sentiment_correct/len(TESTS)*0.5)*100:.1f}%")
    
    return {
        "tag": tag,
        "total_score": total_score,
        "sentiment_correct": sentiment_correct,
        "max_score": len(TESTS),
        "schema_success_rate": total_score / len(TESTS),
        "sentiment_accuracy": sentiment_correct / len(TESTS),
        "combined_rate": (total_score / len(TESTS) * 0.5 + sentiment_correct / len(TESTS) * 0.5),
        "results": results
    }


def run_experiment():
    """Run the extended experiment"""
    print("\n" + "="*80)
    print("  EXTENDED CONTEXT ENGINEERING EXPERIMENT")
    print("  12 Challenging Test Cases")
    print("="*80)
    print(f"\nüìä Test Categories:")
    print("  - 2 Short reviews (positive & neutral)")
    print("  - 2 Pure positive reviews")
    print("  - 2 Pure neutral reviews")
    print("  - 1 Very long review (300+ words)")
    print("  - 3 Edge cases (no clear issue, multiple products, sarcasm)")
    print("  - 2 Tricky cases (disguised negative, extreme negative)\n")
    
    # Run all three contexts
    results_a = eval_context(
        "A: Baseline (minimal instruction)",
        build_context_a_input
    )
    
    if results_a is None:
        return
    
    results_b = eval_context(
        "B: Rules-based (strict format)",
        build_context_b_input
    )
    
    results_c = eval_context(
        "C: Few-shot (with diverse examples)",
        build_context_c_input
    )
    
    # Summary
    print("\n" + "="*80)
    print("  DETAILED COMPARISON")
    print("="*80 + "\n")
    
    print("Schema Correctness (JSON format valid):")
    for name, result in [("Context A", results_a), ("Context B", results_b), ("Context C", results_c)]:
        rate = result["schema_success_rate"]
        bar = "‚ñà" * int(rate * 30)
        print(f"{name:20s} {bar:30s} {rate*100:5.1f}% ({result['total_score']}/{result['max_score']})")
    
    print("\nSentiment Accuracy (matches expected sentiment):")
    for name, result in [("Context A", results_a), ("Context B", results_b), ("Context C", results_c)]:
        rate = result["sentiment_accuracy"]
        bar = "‚ñà" * int(rate * 30)
        print(f"{name:20s} {bar:30s} {rate*100:5.1f}% ({result['sentiment_correct']}/{result['max_score']})")
    
    print("\nCombined Success Rate (50% schema + 50% sentiment):")
    for name, result in [("Context A", results_a), ("Context B", results_b), ("Context C", results_c)]:
        rate = result["combined_rate"]
        bar = "‚ñà" * int(rate * 30)
        print(f"{name:20s} {bar:30s} {rate*100:5.1f}%")
    
    # Save results
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"experiment_results_extended_{timestamp}.json"
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump({
            "timestamp": timestamp,
            "test_count": len(TESTS),
            "results": {
                "context_a": results_a,
                "context_b": results_b,
                "context_c": results_c
            }
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìä Detailed results saved to: {output_file}")


if __name__ == "__main__":
    try:
        run_experiment()
        
        print("\n" + "="*80)
        print("  KEY INSIGHTS")
        print("="*80)
        print("\nThis extended test set reveals:")
        print("  1. How well each context handles positive vs negative reviews")
        print("  2. Ability to detect sarcasm and disguised negativity")
        print("  3. Performance on edge cases (multiple products, no clear issue)")
        print("  4. Consistency across short and very long reviews")
        print("\n‚ú® Few-shot learning typically excels at nuanced sentiment detection!")
        
    except Exception as e:
        print(f"\n‚ùå Experiment failed: {str(e)}")
        import traceback
        traceback.print_exc()
